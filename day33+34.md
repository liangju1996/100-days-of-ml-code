# 随机森林
### 什么是随机森林？
随机森林是有监督的集成学习模型（ensemble——learning model），主要用于分类和回归。  
随机森林建立了很多决策树，然后将其集成，以获得更准确和稳定的预测。
#### 实例
![实例]()
集成学习模型复合了多个机器学习模型（这里☞决策树），使得整体性能更好。  
究其逻辑，每一个模型的个体在单独使用时效果是薄弱的，但是多个模型个体集合在一起的时候，整体的功能会变得强大。  
在随机森林的情况下，单个决策树做出的决策都是“弱”因素，而大量决策树一起被使用时把它们的结果整合，就会产生“强”合奏。
### 随机森林工作原理
随机森林算法分为两步。
> 第一步，创建决策树；    
> 第二步，根据第一步中决策树的分类器结果做出预测。  
#### 创建
每棵树按如下方式生成：  
>1.（数据的随机选取）如果训练集中有N个样本，有放回的随机抽取n个。这个样本将是生成该决策树的训练集。  
>2.（特征的随机选取）对于每个样本，如果有M个输入变量（或特征），指定一个常数m，
然后随机地从M个特征中选取m个特征子集。然后将m个特征中最优的分裂特征用来分割节点。
#### 预测
随机森林的预测分为以下三步：
1.使用每一个随机创建的决策树
2.计算每个预测目标的票数（目标）
3.获得票数最高的预测目标视为随机森林算法的最终预测。

### 随机森林算法与决策树算法的区别：
在随机森林中，查找根节点和分割特征节点的过程是随机进行的。

