# [随机森林](https://blog.csdn.net/edogawachia/article/details/79357844)
### 什么是随机森林？
随机森林是有监督的集成学习模型（ensemble——learning model），主要用于分类和回归。  
随机森林建立了很多决策树，然后将其集成，以获得更准确和稳定的预测。
#### 实例
![实例](https://github.com/liangju1996/100-days-of-ml-code/blob/master/图片/随机森林1.png)  
集成学习模型复合了多个机器学习模型（这里☞决策树），使得整体性能更好。  
究其逻辑，每一个模型的个体在单独使用时效果是薄弱的，但是多个模型个体集合在一起的时候，整体的功能会变得强大。  
在随机森林的情况下，单个决策树做出的决策都是“弱”因素，而大量决策树一起被使用时把它们的结果整合，就会产生“强”合奏。
### 随机森林工作原理
随机森林算法分为两步。
> 第一步，创建决策树；    
> 第二步，根据第一步中决策树的分类器结果做出预测。  
#### 创建
每棵树按如下方式生成：  
>1.（数据的随机选取）如果训练集中有N个样本，有放回的随机抽取n个。这个样本将是生成该决策树的训练集。  
>2.（特征的随机选取）对于每个样本，如果有M个输入变量（或特征），指定一个常数m，
然后随机地从M个特征中选取m个特征子集。然后将m个特征中最优的分裂特征用来分割节点。
#### 预测
随机森林的预测分为以下三步：
1.使用每一个随机创建的决策树
2.计算每个预测目标的票数（目标）
3.获得票数最高的预测目标视为随机森林算法的最终预测。

### 随机森林算法与决策树算法的区别：
在随机森林中，查找根节点和分割特征节点的过程是随机进行的。  

决策树
![决策树](https://github.com/liangju1996/100-days-of-ml-code/blob/master/图片/决策树.png)
随机森林  
![随机森林](https://github.com/liangju1996/100-days-of-ml-code/blob/master/图片/决策树%2B随机森林.png)

### 代码
```ptthon
# 导入库
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# 导入数据集
dataset = pd.read_csv('Social_Network_Ads.csv')
X = dataset.iloc[:, [2, 3]].values
y = dataset.iloc[:, 4].values

# 将数据集拆分为训练集和测试集
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.25, random_state = 0)

# 特征缩放
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
```

[sklearn.ensemble](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
```python
# 调用训练集的随机森林
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

# 预测测试集结果
y_pred = classifier.predict(X_test)

# 生成混淆矩阵，也称作误差矩阵
from sklearn .metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

# 将训练集结果可视化
from matplotlib.colors import ListedColormap
X_set, y_set = X_train, y_train
X1, X2 = np.meshgrid(np.arange(start = X_test[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X.min(), X2.max())
for i,j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Random Forest Classification(Training set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()

# 将测试集结果可视化
from matplotlib.colors import ListedColormap
X_set, y_set = X_test, y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X.min(), X2.max())
for i,j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Random Forest Classification(Training set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()
```
